{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow-coursera-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFelnRPaqnuhpmVU+qeWbz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drugescu/tensorflow-practice/blob/master/tensorflow_coursera_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsw1bwGILMsa",
        "colab_type": "code",
        "outputId": "4f6e0a57-f785-496b-d15a-2bc34bebb601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPY3NcWdLP10",
        "colab_type": "code",
        "outputId": "35499e59-8049-4bcb-9826-ccd773cedd31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_5dH8t3MIW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "      keras.layers.Flatten(input_shape = (28, 28)),\n",
        "      keras.layers.Dense(128, activation = tf.nn.relu),\n",
        "      keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RZocWgMMml3",
        "colab_type": "code",
        "outputId": "a492f062-a056-4352-e1dc-50a64d9f49c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_images[0])\n",
        "print(train_labels[0])\n",
        "print(train_images[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
            "    0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
            "   54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
            "  144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
            "  107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
            "  216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
            "  223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
            "  235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
            "  180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
            "  169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
            "  198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
            "  232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
            "  222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
            "  211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
            "  224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
            "  255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
            "  188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
            "  168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
            "  239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
            "  199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
            "  195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
            "  210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
            "  182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQcjnTfpM1n3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPqyd1PoM70J",
        "colab_type": "code",
        "outputId": "a7b10661-7272-4a33-ec1c-523f374611cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model.compile(optimizer = tf.train.AdamOptimizer(), loss = 'sparse_categorical_crossentropy')\n",
        "model.fit(train_images, train_labels, epochs = 5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 14s 230us/sample - loss: 0.4989\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.3740\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.3359\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.3110\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fecf8372400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i41Rf_HQNY5j",
        "colab_type": "code",
        "outputId": "fda1694e-eb71-4094-abbc-e872ba21abd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 62us/sample - loss: 0.3551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35514966825246813"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eJScdcjN2eV",
        "colab_type": "code",
        "outputId": "6fbf3377-09da-47f7-f6d8-2f09ef9a979a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.8492375e-06 6.0696031e-08 1.1498990e-06 1.5131602e-07 5.0895073e-06\n",
            " 2.2734063e-02 3.4767076e-05 2.8721614e-02 1.9273941e-06 9.4849831e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjqAG39bN7fD",
        "colab_type": "code",
        "outputId": "a03bca5e-71c0-4a65-ac9c-ee82135f6a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIT21rtWOaCz",
        "colab_type": "code",
        "outputId": "b9e466f7-c8e6-403c-88da-54c25a7319a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs = 15)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 9s 152us/sample - loss: 0.2027\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 9s 149us/sample - loss: 0.0997\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 9s 148us/sample - loss: 0.0714\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 9s 149us/sample - loss: 0.0550\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 9s 149us/sample - loss: 0.0470\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 9s 147us/sample - loss: 0.0383\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 9s 149us/sample - loss: 0.0343\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 9s 148us/sample - loss: 0.0321\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 9s 147us/sample - loss: 0.0301\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 9s 147us/sample - loss: 0.0275\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 9s 146us/sample - loss: 0.0208\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 9s 148us/sample - loss: 0.0229\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 9s 147us/sample - loss: 0.0218\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 9s 150us/sample - loss: 0.0195\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 9s 150us/sample - loss: 0.0176\n",
            "10000/10000 [==============================] - 1s 84us/sample - loss: 0.1338\n",
            "[0.0000000e+00 5.1898130e-23 5.3423071e-18 1.1579194e-24 1.6903466e-21\n",
            " 9.3987924e-38 0.0000000e+00 1.0000000e+00 5.1442647e-22 5.1374010e-22]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgG5y1qpQuRM",
        "colab_type": "code",
        "outputId": "396fb3e0-8e2c-4933-80ad-fe71d37a061a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss') < 0.02):\n",
        "      print(\"\\nReached 98% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(2304, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(600, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(100, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=65, callbacks=[callbacks])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "Train on 60000 samples\n",
            "Epoch 1/65\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4797 - acc: 0.8241\n",
            "Epoch 2/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.3646 - acc: 0.8658\n",
            "Epoch 3/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.3275 - acc: 0.8799\n",
            "Epoch 4/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3020 - acc: 0.8884\n",
            "Epoch 5/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2817 - acc: 0.8936\n",
            "Epoch 6/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2666 - acc: 0.8994\n",
            "Epoch 7/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2585 - acc: 0.9036\n",
            "Epoch 8/65\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2428 - acc: 0.9086\n",
            "Epoch 9/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2352 - acc: 0.9112\n",
            "Epoch 10/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2248 - acc: 0.9147\n",
            "Epoch 11/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2193 - acc: 0.9161\n",
            "Epoch 12/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2082 - acc: 0.9204\n",
            "Epoch 13/65\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2012 - acc: 0.9226\n",
            "Epoch 14/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1972 - acc: 0.9252\n",
            "Epoch 15/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1908 - acc: 0.9274\n",
            "Epoch 16/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1846 - acc: 0.9291\n",
            "Epoch 17/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1766 - acc: 0.9323\n",
            "Epoch 18/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1785 - acc: 0.9326\n",
            "Epoch 19/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1729 - acc: 0.9341\n",
            "Epoch 20/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1652 - acc: 0.9370\n",
            "Epoch 21/65\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1625 - acc: 0.9384\n",
            "Epoch 22/65\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1548 - acc: 0.9401\n",
            "Epoch 23/65\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1570 - acc: 0.9403\n",
            "Epoch 24/65\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1487 - acc: 0.9423\n",
            "Epoch 25/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1446 - acc: 0.9434\n",
            "Epoch 26/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1427 - acc: 0.9453\n",
            "Epoch 27/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1393 - acc: 0.9471\n",
            "Epoch 28/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1385 - acc: 0.9484\n",
            "Epoch 29/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1322 - acc: 0.9509\n",
            "Epoch 30/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1396 - acc: 0.9492\n",
            "Epoch 31/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1296 - acc: 0.9510\n",
            "Epoch 32/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1228 - acc: 0.9528\n",
            "Epoch 33/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1214 - acc: 0.9534\n",
            "Epoch 34/65\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1194 - acc: 0.9541\n",
            "Epoch 35/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1158 - acc: 0.9554\n",
            "Epoch 36/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1223 - acc: 0.9541\n",
            "Epoch 37/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1151 - acc: 0.9567\n",
            "Epoch 38/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1086 - acc: 0.9581\n",
            "Epoch 39/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1119 - acc: 0.9580\n",
            "Epoch 40/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1112 - acc: 0.9588\n",
            "Epoch 41/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1047 - acc: 0.9611\n",
            "Epoch 42/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1070 - acc: 0.9597\n",
            "Epoch 43/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1029 - acc: 0.9614\n",
            "Epoch 44/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1083 - acc: 0.9612\n",
            "Epoch 45/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0966 - acc: 0.9635\n",
            "Epoch 46/65\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0926 - acc: 0.9645\n",
            "Epoch 47/65\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0977 - acc: 0.9632\n",
            "Epoch 48/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0934 - acc: 0.9645\n",
            "Epoch 49/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0962 - acc: 0.9641\n",
            "Epoch 50/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0853 - acc: 0.9672\n",
            "Epoch 51/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0865 - acc: 0.9665\n",
            "Epoch 52/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.0913 - acc: 0.9654\n",
            "Epoch 53/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0871 - acc: 0.9678\n",
            "Epoch 54/65\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.0855 - acc: 0.9675\n",
            "Epoch 55/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0919 - acc: 0.9670\n",
            "Epoch 56/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.0915 - acc: 0.9675\n",
            "Epoch 57/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0746 - acc: 0.9709\n",
            "Epoch 58/65\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0846 - acc: 0.9692\n",
            "Epoch 59/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.0887 - acc: 0.9694\n",
            "Epoch 60/65\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0750 - acc: 0.9725\n",
            "Epoch 61/65\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0730 - acc: 0.9726\n",
            "Epoch 62/65\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0789 - acc: 0.9704\n",
            "Epoch 63/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.0774 - acc: 0.9724\n",
            "Epoch 64/65\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.0702 - acc: 0.9738\n",
            "Epoch 65/65\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0740 - acc: 0.9722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe96c17b160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5u7_HYoVEGZ",
        "colab_type": "code",
        "outputId": "290637ce-dbc4-4d4e-d004-749a9b1565d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 - 0s - loss: 0.8069 - acc: 0.8952\n",
            "\n",
            "Test accuracy: 0.8952\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}